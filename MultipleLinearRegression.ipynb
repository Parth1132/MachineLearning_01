{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrHJ/iVaOfcOoKJg5Rncvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parth1132/MachineLearning_01/blob/main/MultipleLinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Numpy`:- A popular library for scientific computing\n",
        "\n",
        "`Matplotlib`:- A popular library for plotting data"
      ],
      "metadata": {
        "id": "SGzqUqJISEcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=2) #Reduced display precision on numpy arrays"
      ],
      "metadata": {
        "id": "ejSBtQ6sSUNZ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating `X_train` and `y_train` variables"
      ],
      "metadata": {
        "id": "rmWFDGHwTE44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
        "y_train = np.array([460, 232, 178])"
      ],
      "metadata": {
        "id": "VSttf5wQTL1z"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the `input` data"
      ],
      "metadata": {
        "id": "4cDBY5PrTx4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data is stored in numpy array/matrix\n",
        "print(f\"X Shape: {X_train.shape}, X type: {type(X_train)}\")\n",
        "print(X_train)\n",
        "print(f\"y Shape: {y_train.shape}, y type:{type(y_train)}\")\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFLi-0oqT0Xc",
        "outputId": "c25d6d17-c1e9-41f8-f0a1-7c63fb513c7a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (3, 4), X type: <class 'numpy.ndarray'>\n",
            "[[2104    5    1   45]\n",
            " [1416    3    2   40]\n",
            " [ 852    2    1   35]]\n",
            "y Shape: (3,), y type:<class 'numpy.ndarray'>\n",
            "[460 232 178]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter vector w, b\n",
        "\n",
        "\n",
        "\n",
        "*   `w` is a vector with *n* elements\n",
        "    * Each element contains a parameter associated with one feature.\n",
        "    * In our dataset, n is 4.\n",
        "    * Notionally, we draw this as a column vector.\n",
        "\n",
        "\n",
        "*    `b` is a scalar parameter\n",
        "\n",
        "*    `w` is a 1-D Numpy vector\n",
        "\n"
      ],
      "metadata": {
        "id": "e8zbEMQwVtJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For demonstration, w and b will be loaded with some initial values that are near the optimal.\n",
        "\n",
        "b_init = 785.1811367994083\n",
        "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
        "print(f\"w_init shape: {w_init.shape}, b_init type:{type(b_init)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPhss5jsWvWJ",
        "outputId": "558432bb-5320-45fe-839e-7105097bfea7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w_init shape: (4,), b_init type:<class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single Prediction element by element**"
      ],
      "metadata": {
        "id": "XdxqDjUmYhR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_loop(x, w, b):\n",
        "  \"\"\"\n",
        "  single predict using linear regression\n",
        "\n",
        "  Args:\n",
        "  x (ndarray)\n",
        "  w (ndarray)\n",
        "\n",
        "  b(scalar): Model parameter\n",
        "\n",
        "  return p (scalar) : prediction\n",
        "  \"\"\"\n",
        "\n",
        "  n = x.shape[0]\n",
        "  p = 0\n",
        "\n",
        "  for i in range(n):\n",
        "    p_i = x[i] * w[i]\n",
        "    p = p + p_i\n",
        "\n",
        "  p = p + b\n",
        "  return p"
      ],
      "metadata": {
        "id": "kyDQGVPAYnEx"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get a row from out training data\n",
        "\n",
        "x_vec = X_train[0,:]\n",
        "print(f\" x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
        "\n",
        "#make  prediction\n",
        "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
        "print(f\"f_wb Shape {f_wb.shape}, prediction:{f_wb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTYDW5HsrAs2",
        "outputId": "03969c5b-3876-48db-f539-13c0d3e7d686"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " x_vec shape (4,), x_vec value: [2104    5    1   45]\n",
            "f_wb Shape (), prediction:459.9999976194083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single prediction, Vector\n",
        "--`np.dot()` can be used to perform a vector dot product"
      ],
      "metadata": {
        "id": "UZ1yxZvVsSKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, w, b):\n",
        "\n",
        "  \"\"\"\n",
        "  single predict using linear regression\n",
        "\n",
        "  Args:\n",
        "\n",
        "  x (ndarray)\n",
        "  y (ndarray)\n",
        "  b (scalar)\n",
        "\n",
        "  Returns:\n",
        "  p (scalar) : prediction\n",
        "  \"\"\"\n",
        "  p = np.dot(x, w) + b\n",
        "  return p"
      ],
      "metadata": {
        "id": "0_8BjmWLsrbT"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get a row from the training data\n",
        "x_vec = X_train[0,:]\n",
        "print(f\"x_vec Shape {x_vec.shape}, x_vec value:{x_vec}\")\n",
        "\n",
        "#make a prediction\n",
        "f_wb = predict(x_vec, w_init, b_init)\n",
        "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHVe9qBytQ5w",
        "outputId": "59d5fcbe-bad1-4045-b4ec-f271303b75b4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_vec Shape (4,), x_vec value:[2104    5    1   45]\n",
            "f_wb shape (), prediction: 459.9999976194083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute cost with Multiple Variables"
      ],
      "metadata": {
        "id": "YjTYkPC-veVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, w, b):\n",
        "  \"\"\"\n",
        "  compute cost\n",
        "  Args:\n",
        "  x (ndarray  (m,n)) : Data, m examples with n features\n",
        "  y (ndarray (m,)) : target values\n",
        "  w (ndarray (n,)) : model parameter\n",
        "  b (scalar)       : model parameter\n",
        "\n",
        "  returns:\n",
        "  cost (scalar) : cost\n",
        "  \"\"\"\n",
        "  m = X.shape[0]\n",
        "  cost = 0.0\n",
        "\n",
        "  for i in range(m):\n",
        "    f_wb_i = np.dot(X[i], w) + b\n",
        "    cost = cost + (f_wb_i - y[i])**2\n",
        "  cost = cost / (2 * m)\n",
        "\n",
        "  return cost\n",
        ""
      ],
      "metadata": {
        "id": "zUN7XLx4vjw2"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute and display cost using our pre-chosen optimal parameters\n",
        "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
        "print(type(cost))\n",
        "print(f'cost at optimal w: {cost}')"
      ],
      "metadata": {
        "id": "gCP1954Mw-Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b960aa-7461-4972-8d31-de480bcf30bb"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'>\n",
            "cost at optimal w: 1.5578904428966628e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Gradient with Multiple Variables\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{1}  \\\\\n",
        "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{2}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "--An implementation for calculating equations (partial derivative of (1) and (2) is below"
      ],
      "metadata": {
        "id": "drspTxihy0F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b):\n",
        "  \"\"\"\n",
        "  Computes the gradient for linear regression\n",
        "  Args:\n",
        "  x (ndarray (m,n)): Data, with m examples and n features\n",
        "  y (ndarray (m,)) : target values\n",
        "  w (ndarray (n,)) : model parameters\n",
        "  b (scalar)       : model_Scalar parameter\n",
        "\n",
        "  returns:\n",
        "\n",
        "  dj_dw (ndarray (n,)): Effect of w on function j\n",
        "  dj_db (scalar) : Or can be said as \"The gradient of the cost w.r.t to parameter b.\n",
        "\n",
        "  The partial derivative of the cost function with respect to w_j for a single example is: ∂J / ∂w_j = 2 * error_i * x_j_i\n",
        "  \"\"\"\n",
        "  m,n= X.shape\n",
        "  dj_dw = np.zeros((n,))\n",
        "\n",
        "  dj_db = 0\n",
        "\n",
        "  for i in range(m):\n",
        "    err = (np.dot(X[i], w) + b) - y[i]\n",
        "    for j in range(n):\n",
        "      dj_dw[j] = dj_dw[j] + err * X[i, j] #---CHECK DOCSTRING FOR REFERENCE\n",
        "    dj_db = dj_db + err\n",
        "\n",
        "  dj_dw = dj_dw / m\n",
        "  dj_db = dj_db / m\n",
        "\n",
        "  return dj_db, dj_dw\n",
        "\n"
      ],
      "metadata": {
        "id": "_hEKvIhY1tf7"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute and display gradient\n",
        "\n",
        "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
        "print(f\"dj_db at initial w,b: {tmp_dj_db}\")\n",
        "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qEvRNB98hqw",
        "outputId": "ac16d32f-c1af-47fb-ac71-58490c08d178"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dj_db at initial w,b: -1.6739251501955248e-06\n",
            "dj_dw at initial w,b: \n",
            " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
        "    \"\"\"\n",
        "    Performs batch gradient descent to learn theta. Updates theta by taking\n",
        "    num_iters gradient steps with learning rate alpha\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n))   : Data, m examples with n features\n",
        "      y (ndarray (m,))    : target values\n",
        "      w_in (ndarray (n,)) : initial model parameters\n",
        "      b_in (scalar)       : initial model parameter\n",
        "      cost_function       : function to compute cost\n",
        "      gradient_function   : function to compute the gradient\n",
        "      alpha (float)       : Learning rate\n",
        "      num_iters (int)     : number of iterations to run gradient descent\n",
        "\n",
        "    Returns:\n",
        "      w (ndarray (n,)) : Updated values of parameters\n",
        "      b (scalar)       : Updated value of parameter\n",
        "      \"\"\"\n",
        "\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
        "    b = b_in\n",
        "\n",
        "    for i in range(num_iters):\n",
        "\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w = w - alpha * dj_dw               ##None\n",
        "        b = b - alpha * dj_db               ##None\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            J_history.append(cost_function(X, y, w, b))\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i % math.ceil(num_iters / 10) == 0:\n",
        "          print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")  # Assuming a 1D array\n",
        "\n",
        "    return w, b, J_history #return final w,b and J history for graphing"
      ],
      "metadata": {
        "id": "LcQYg781-hHW"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize parameters\n",
        "initial_w = np.zeros_like(w_init)\n",
        "initial_b = 0\n",
        "# some gradient descent settings\n",
        "iterations = 1000\n",
        "alpha = 5.0e-7\n",
        "# run gradient descent\n",
        "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,compute_cost, compute_gradient, alpha, iterations)\n",
        "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
        "m,_ = X_train.shape\n",
        "for i in range(m):\n",
        "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ctRB5I3Go9k",
        "outputId": "a5abe97f-d0c5-4498-ed46-6be3f7852707"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration    0: Cost  2529.46   \n",
            "Iteration  100: Cost   695.99   \n",
            "Iteration  200: Cost   694.92   \n",
            "Iteration  300: Cost   693.86   \n",
            "Iteration  400: Cost   692.81   \n",
            "Iteration  500: Cost   691.77   \n",
            "Iteration  600: Cost   690.73   \n",
            "Iteration  700: Cost   689.71   \n",
            "Iteration  800: Cost   688.70   \n",
            "Iteration  900: Cost   687.69   \n",
            "b,w found by gradient descent: -0.00,[ 0.2   0.   -0.01 -0.07] \n",
            "prediction: 426.19, target value: 460\n",
            "prediction: 286.17, target value: 232\n",
            "prediction: 171.47, target value: 178\n"
          ]
        }
      ]
    }
  ]
}